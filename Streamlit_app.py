import streamlit as st
import time
import pandas as pd
import numpy as np
from collections import deque
import random
import cv2 # Se incluir√≠a para leer la c√°mara USB real en la Jetson, aqu√≠ se usa para simular un frame

# --- CONFIGURACI√ìN GENERAL DE LA P√ÅGINA ---
st.set_page_config(
    page_title="Detecci√≥n de Cuerpos Extra√±os en Man√≠ (Supervisor)",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- CONSTANTES Y SIMULACI√ìN DE CLASES ---
# Simulaci√≥n de las clases basado en tu data.yaml
CLASSES = {0: "Man√≠ (Normal)", 1: "Cuerpo Extra√±o (Piedra)", 2: "Cuerpo Extra√±o (C√°scara)", 3: "Man√≠ Da√±ado"}
FOREIGN_CLASSES = [1, 2] # IDs de las clases que son "cuerpos extra√±os"
INFERENCE_LATENCY_SECONDS = 2.0 # Tu tiempo de inferencia reportado

# Buffer para almacenar las √∫ltimas inferencias (para estad√≠sticas)
MAX_BUFFER_SIZE = 50
inference_history = deque(maxlen=MAX_BUFFER_SIZE)

# Funci√≥n para simular la carga y ejecuci√≥n del modelo ONNX/SAHI
@st.cache_resource
def load_and_warmup_model(onnx_path="best.onnx"):
    """
    Carga el modelo ONNX y realiza un 'warmup'.
    En la implementaci√≥n real, aqu√≠ se cargar√≠a el motor ONNX (por ejemplo, con ONNX Runtime
    o un motor optimizado para Jetson como TensorRT si se usa un .engine) y la configuraci√≥n SAHI.
    """
    st.write(f"‚öôÔ∏è Cargando modelo {onnx_path} y preparando entorno...")
    time.sleep(1) # Simula la carga
    st.success("‚úÖ Modelo y configuraci√≥n SAHI cargados correctamente.")
    return "Modelo ONNX/SAHI (Simulado)"

# Funci√≥n que simula la inferencia real
def perform_sahi_inference(model, frame):
    """
    Simula el proceso de inferencia real:
    1. Divide la imagen con SAHI.
    2. Ejecuta el modelo YoloV8 ONNX en los recortes.
    3. Combina los resultados.

    Retorna: (frame_con_detecciones, resultados_deteccion_dict)
    """
    start_time = time.time()
    time.sleep(INFERENCE_LATENCY_SECONDS) # Simula la latencia de 2s

    # Simulaci√≥n de resultados de detecci√≥n:
    # Genera una lista de detecciones simuladas
    num_detections = random.randint(5, 15)
    detections = []
    for _ in range(num_detections):
        # Simula: [xmin, ymin, xmax, ymax, confianza, clase_id]
        class_id = random.choices(list(CLASSES.keys()), weights=[0.85, 0.05, 0.05, 0.05])[0]
        detections.append({
            'class_id': class_id,
            'class_name': CLASSES[class_id],
            'confidence': random.uniform(0.7, 0.99)
        })

    end_time = time.time()
    latency = end_time - start_time

    # Simulaci√≥n de dibujar bounding boxes en el frame
    # (En la implementaci√≥n real, esto usar√≠a cv2.rectangle o similar)
    # Aqu√≠ simplemente se retorna el frame de simulaci√≥n (que no se modifica realmente)

    return frame, detections, latency


# --- BARRA LATERAL (CONFIGURACI√ìN) ---
st.sidebar.title("üõ†Ô∏è Configuraci√≥n del Sistema")

# 1. Par√°metro de Configuraci√≥n: Intervalo de Inferencia
st.sidebar.markdown("---")
st.sidebar.header("Control de Inferencias")
# El m√≠nimo de inferencia debe ser el tiempo de procesamiento (2s)
min_interval = INFERENCE_LATENCY_SECONDS
default_interval = max(min_interval, 3.0)

inference_interval = st.sidebar.slider(
    'Intervalo entre Inferencias (segundos)',
    min_value=min_interval,
    max_value=10.0,
    value=default_interval,
    step=0.5,
    help=f"Tiempo que el sistema espera antes de tomar el siguiente frame para procesar. Debe ser >= {min_interval}s."
)
st.sidebar.info(f"El modelo demora **{INFERENCE_LATENCY_SECONDS}s** en procesar una imagen.")

# 2. Simulaci√≥n de la C√°mara USB (Placeholder/Control)
st.sidebar.markdown("---")
st.sidebar.header("Fuente de Video")
if st.sidebar.checkbox("Simular C√°mara USB Activa", value=True):
    # En la implementaci√≥n real, aqu√≠ se inicializar√≠a cv2.VideoCapture(0)
    st.sidebar.success("C√°mara USB (Simulada) ON")
else:
    st.sidebar.warning("C√°mara USB (Simulada) OFF. El procesamiento est√° pausado.")

# Inicializar/Cargar el Modelo
st.sidebar.markdown("---")
st.sidebar.header("Estado del Modelo")
model_placeholder = st.sidebar.empty() # Placeholder para mostrar el estado de la carga
with model_placeholder:
    model = load_and_warmup_model() # Carga el modelo (solo se ejecuta una vez)

# --- CUERPO PRINCIPAL DE LA APLICACI√ìN (VISUALIZACI√ìN Y ESTAD√çSTICAS) ---
st.title("Sistema de Detecci√≥n de Cuerpos Extra√±os en Man√≠ ü•ú (JETSON NANO)")
st.markdown("Acceso para Supervisores. Muestra detecciones en tiempo real y m√©tricas.")

# Contenedor principal para visualizaci√≥n
col_video, col_stats = st.columns([2, 1])

# --- Columna de Video/Detecci√≥n ---
with col_video:
    st.header("Visualizaci√≥n en Tiempo Real")
    video_placeholder = st.empty() # Placeholder para el frame del video
    status_placeholder = st.empty() # Placeholder para el estado de la inferencia

# --- Columna de Estad√≠sticas ---
with col_stats:
    st.header("Estad√≠sticas de Lote")
    # Indicadores Clave
    kpi1, kpi2 = st.columns(2)
    kpi_total_detections = kpi1.empty()
    kpi_foreign_rate = kpi2.empty()

    # Historial / Tabla de Lote
    st.subheader("Historial Reciente (√öltimas Detecciones)")
    stats_table_placeholder = st.empty()
    chart_placeholder = st.empty()

# --- Bucle de Procesamiento (El coraz√≥n de la aplicaci√≥n) ---
if st.sidebar.checkbox("Simular C√°mara USB Activa", value=True):
    # Inicializar el contador de frames y la √∫ltima inferencia
    frame_counter = 0
    last_inference_time = time.time()

    while True:
        # 1. Captura de Frame (Simulada)
        # En la vida real, usar√≠amos cap.read() si se inicializ√≥ cv2.VideoCapture(0)
        # Aqu√≠ creamos un frame simulado (fondo gris)
        frame = np.zeros((480, 640, 3), dtype=np.uint8) + 50
        frame_counter += 1

        # 2. Decisi√≥n de Inferencia
        current_time = time.time()
        time_since_last_inference = current_time - last_inference_time

        if time_since_last_inference >= inference_interval:
            # --- REALIZAR INFERENCIA ---
            status_placeholder.warning(f"‚è≥ Procesando Frame {frame_counter}...")
            frame_processed, detections, latency = perform_sahi_inference(model, frame)
            last_inference_time = current_time

            # A√±adir resultados al historial
            foreign_count = sum(1 for det in detections if det['class_id'] in FOREIGN_CLASSES)
            total_detections = len(detections)
            inference_history.append({
                'Time': pd.Timestamp.now().strftime('%H:%M:%S'),
                'Total_Detections': total_detections,
                'Foreign_Count': foreign_count,
                'Foreign_Rate': (foreign_count / total_detections) if total_detections else 0,
                'Latency_s': round(latency, 2)
            })

            # 3. Actualizar Visualizaci√≥n
            # Dibujar el contador de cuerpos extra√±os en la simulaci√≥n
            if foreign_count > 0:
                 cv2.putText(frame_processed, f"CUERPO EXTRA√ëO DETECTADO: {foreign_count}", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)
            else:
                 cv2.putText(frame_processed, "Producci√≥n Limpia", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3)

            # Convertir el frame (OpenCV BGR) a RGB para Streamlit
            frame_rgb = cv2.cvtColor(frame_processed, cv2.COLOR_BGR2RGB)
            video_placeholder.image(frame_rgb, caption=f"Frame #{frame_counter} | Detecciones: {total_detections}", use_column_width=True)
            status_placeholder.success(f"‚úÖ Inferencia completada en {latency:.2f}s. Cuerpos Extra√±os: {foreign_count}.")

            # 4. Actualizar Estad√≠sticas
            df_history = pd.DataFrame(inference_history)

            if not df_history.empty:
                # KPI 1: Detecciones Totales en el Lote
                total_foreign = df_history['Foreign_Count'].sum()
                kpi_total_detections.metric("Cuerpos Extra√±os (Lote)", f"{total_foreign} unid.")

                # KPI 2: Tasa Promedio de Cuerpos Extra√±os
                avg_rate = df_history['Foreign_Rate'].mean() * 100
                kpi_foreign_rate.metric("Tasa Promedio (%)", f"{avg_rate:.2f} %")

                # Tabla de Historial
                stats_table_placeholder.dataframe(
                    df_history[['Time', 'Total_Detections', 'Foreign_Count', 'Foreign_Rate', 'Latency_s']]
                    .rename(columns={'Foreign_Count': 'Extra√±os', 'Total_Detections': 'Total', 'Foreign_Rate': 'Tasa (%)', 'Latency_s': 'Latencia (s)'})
                    .sort_values(by='Time', ascending=False)
                    .head(10),
                    use_container_width=True,
                    hide_index=True
                )

                # Gr√°fico de Tasa de Extra√±os
                chart_placeholder.line_chart(df_history['Foreign_Rate'].rename('Tasa de Cuerpos Extra√±os'))

        else:
            # No es tiempo de inferencia, solo mostrar el frame 'vivo' (sin procesamiento)
            frame_display = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            cv2.putText(frame_display, "Esperando proxima inferencia...", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            video_placeholder.image(frame_display, caption=f"Esperando... Siguiente en {inference_interval - time_since_last_inference:.1f}s", use_column_width=True)

        # Peque√±a pausa para evitar que el bucle consuma demasiado CPU cuando no est√° haciendo inferencia.
        # Es clave para aplicaciones en bucle en Streamlit.
        time.sleep(0.1)

else:
    # Estado cuando la c√°mara no est√° activa
    st.warning("El sistema est√° inactivo. Por favor, active la 'Simular C√°mara USB Activa' en la barra lateral para iniciar la detecci√≥n.")