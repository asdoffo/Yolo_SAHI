# ü•ú Sistema de Detecci√≥n de Cuerpos Extra√±os en Man√≠

Pipeline completo para detectar objetos peque√±os (piedras, palitos, metal, pl√°stico) en im√°genes de alta resoluci√≥n de man√≠ usando YOLOv8 y SAHI (Slicing Aided Hyper Inference).

## üìã Caracter√≠sticas

- ‚úÖ **Procesamiento de im√°genes de alta resoluci√≥n** (3840x2160px)
- ‚úÖ **Detecci√≥n de objetos peque√±os** (200x200px) con alta precisi√≥n
- ‚úÖ **Estrategia de tiling/cropping** para mantener resoluci√≥n
- ‚úÖ **Post-procesamiento avanzado** con NMS optimizado
- ‚úÖ **Comparaci√≥n de m√©todos** (est√°ndar vs SAHI)
- ‚úÖ **Exportaci√≥n a m√∫ltiples formatos** (ONNX, TensorRT, etc.)

## üöÄ Instalaci√≥n R√°pida

### Opci√≥n 1: Script autom√°tico
```bash
chmod +x install_dependencies.sh
./install_dependencies.sh
```

### Opci√≥n 2: Con pip
```bash
pip install -r requirements.txt
```

### Opci√≥n 3: Manual
```bash
# PyTorch con CUDA 11.8
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# Dependencias principales
pip install ultralytics sahi opencv-python matplotlib tqdm
```

## üìÅ Estructura del Proyecto

```
proyecto/
‚îú‚îÄ‚îÄ datasets/
‚îÇ   ‚îú‚îÄ‚îÄ original/          # Dataset original (3840x2160)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ images/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train/     # Im√°genes de entrenamiento
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ val/       # Im√°genes de validaci√≥n
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ labels/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ train/     # Anotaciones YOLO
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ val/
‚îÇ   ‚îî‚îÄ‚îÄ tiled/            # Dataset procesado (640x640)
‚îú‚îÄ‚îÄ models/               # Modelos entrenados
‚îú‚îÄ‚îÄ output/               # Resultados de inferencia
‚îú‚îÄ‚îÄ runs/                 # Logs de entrenamiento
‚îî‚îÄ‚îÄ scripts/
    ‚îú‚îÄ‚îÄ dataset_preparation.py  # Preparaci√≥n con tiling
    ‚îú‚îÄ‚îÄ train_model.py         # Entrenamiento
    ‚îî‚îÄ‚îÄ inference_sahi.py      # Inferencia
```

## üîß Pipeline Completo

### 1Ô∏è‚É£ Preparaci√≥n del Dataset

Divide las im√°genes grandes en tiles de 640x640 con overlap:

```bash
python dataset_preparation.py \
    --source datasets/original \
    --output datasets/tiled \
    --tile-size 640 \
    --overlap 0.2 \
    --classes piedra palito metal plastico
```

**Par√°metros importantes:**
- `--tile-size`: Tama√±o de cada tile (default: 640)
- `--overlap`: Superposici√≥n entre tiles (default: 0.2 = 20%)
- `--keep-empty`: Mantener tiles sin objetos (√∫til para reducir falsos positivos)

**Resultado esperado:**
- Una imagen de 3840x2160 genera ~42 tiles con 20% de overlap
- Las anotaciones se ajustan autom√°ticamente para cada tile

### 2Ô∏è‚É£ Entrenamiento del Modelo

Entrena YOLOv8 optimizado para objetos peque√±os:

```bash
python train_model.py \
    --data datasets/tiled/data.yaml \
    --model x \
    --epochs 200 \
    --img-size 640 \
    --batch-size 16 \
    --device 0
```

**Configuraciones recomendadas por GPU:**

| GPU | VRAM | Modelo | Batch Size | Img Size |
|-----|------|--------|------------|----------|
| RTX 3060 | 12GB | YOLOv8x | 8 | 640 |
| RTX 3080 | 10GB | YOLOv8l | 12 | 640 |
| RTX 4090 | 24GB | YOLOv8x | 16 | 1280 |
| T4 | 16GB | YOLOv8x | 12 | 640 |

**Hiperpar√°metros optimizados (ya incluidos):**
- Augmentation espec√≠fica para objetos peque√±os
- Copy-paste augmentation (0.3)
- Mosaic reducido (0.5)
- Mayor peso a p√©rdida de bbox (7.5)

### 3Ô∏è‚É£ Inferencia con SAHI

Procesa im√°genes de alta resoluci√≥n con slicing:

```bash
# Imagen individual
python inference_sahi.py \
    --model runs/detect/*/weights/best.pt \
    --image test_image.jpg \
    --conf 0.25 \
    --visualize

# Lote de im√°genes
python inference_sahi.py \
    --model runs/detect/*/weights/best.pt \
    --folder test_images/ \
    --conf 0.25

# Comparar m√©todos
python inference_sahi.py \
    --model runs/detect/*/weights/best.pt \
    --image test_image.jpg \
    --compare
```

## üìä Ejemplos de Uso

### Ejemplo 1: Pipeline Completo

```python
# 1. Preparar dataset
from dataset_preparation import DatasetTiler

tiler = DatasetTiler(
    source_dir="datasets/original",
    output_dir="datasets/tiled",
    tile_size=640,
    overlap=0.2
)
tiler.process_dataset(keep_empty_tiles=False)
tiler.create_data_yaml(['piedra', 'palito', 'metal', 'plastico'])

# 2. Entrenar modelo
from train_model import YOLOTrainer

trainer = YOLOTrainer(
    data_yaml="datasets/tiled/data.yaml",
    model_size='x',
    device='0'
)
trainer.train_model(epochs=200, img_size=640)

# 3. Inferencia
from inference_sahi import PeanutInspector

inspector = PeanutInspector(
    model_path="runs/detect/*/weights/best.pt",
    confidence_threshold=0.25
)
detections, result = inspector.detect_with_sahi(
    "test_image.jpg",
    slice_size=640,
    overlap_ratio=0.2
)
```

### Ejemplo 2: Inferencia en Tiempo Real

```python
import cv2
from inference_sahi import PeanutInspector

inspector = PeanutInspector("models/best.pt")

# Procesar video o stream
cap = cv2.VideoCapture("video.mp4")  # o 0 para webcam

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    # Detectar (puedes procesar cada N frames para mayor velocidad)
    detections, _ = inspector.detect_with_sahi(frame)
    
    # Dibujar resultados
    for det in detections:
        x1, y1, x2, y2 = det['bbox']
        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
        cv2.putText(frame, f"{det['class']} {det['confidence']:.2f}",
                   (int(x1), int(y1)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    
    cv2.imshow('Detecci√≥n', frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

## ‚ö° Optimizaci√≥n de Rendimiento

### Para Mayor Velocidad:
1. **Reducir overlap**: Usar 0.1 en lugar de 0.2
2. **Modelo m√°s peque√±o**: YOLOv8m o YOLOv8l
3. **Aumentar conf threshold**: 0.35 en lugar de 0.25
4. **Usar TensorRT**: Exportar modelo para GPU NVIDIA
5. **Procesamiento por lotes**: Procesar m√∫ltiples tiles simult√°neamente

### Para Mayor Precisi√≥n:
1. **Aumentar overlap**: Usar 0.3 o 0.4
2. **Modelo m√°s grande**: YOLOv8x
3. **Reducir conf threshold**: 0.15
4. **Aumentar √©pocas**: 300-500 √©pocas
5. **Data augmentation**: M√°s copy-paste y mixup

## üîç Comparaci√≥n de M√©todos

| M√©todo | Ventajas | Desventajas | Uso Recomendado |
|--------|----------|-------------|-----------------|
| **YOLO Est√°ndar** | R√°pido (0.05s) | Pierde objetos peque√±os | Objetos >50px |
| **SAHI (Nuestro)** | Alta precisi√≥n en objetos peque√±os | M√°s lento (2-3s) | Objetos <50px |
| **Imagen completa 1280** | Balance velocidad/precisi√≥n | Requiere m√°s VRAM | GPUs potentes |

## üìà M√©tricas Esperadas

Con el pipeline optimizado deber√≠as obtener:

- **mAP50**: 0.85-0.92
- **mAP50-95**: 0.65-0.75
- **Precisi√≥n**: 0.88-0.94
- **Recall**: 0.82-0.90
- **FPS**: 5-15 (dependiendo del hardware)

## üêõ Soluci√≥n de Problemas

### "CUDA out of memory"
```bash
# Reducir batch size
python train_model.py --batch-size 4

# O usar CPU
python train_model.py --device cpu
```

### "No se detectan objetos"
```python
# Reducir threshold de confianza
inspector = PeanutInspector(model_path, confidence_threshold=0.15)

# Aumentar overlap
detect_with_sahi(image, overlap_ratio=0.3)
```

### "Muchos falsos positivos"
```python
# Aumentar threshold
inspector = PeanutInspector(model_path, confidence_threshold=0.4)

# Mejorar NMS
detect_with_sahi(image, postprocess='GREEDYNMM')
```

## üìö Referencias

- [YOLOv8 Documentation](https://docs.ultralytics.com/)
- [SAHI Documentation](https://github.com/obss/sahi)
- [Ultralytics GitHub](https://github.com/ultralytics/ultralytics)

## üìù Notas Importantes

1. **Calidad de Anotaciones**: La precisi√≥n depende mucho de la calidad de las anotaciones. Aseg√∫rate de que todos los objetos est√©n correctamente etiquetados.

2. **Balance de Clases**: Si tienes desbalance (ej: muchas piedras, pocos pl√°sticos), considera usar weighted loss o data augmentation espec√≠fica.

3. **Validaci√≥n Cruzada**: Usa diferentes splits de validaci√≥n para asegurar que el modelo generaliza bien.

4. **Monitoreo**: Usa herramientas como Weights & Biases o TensorBoard para monitorear el entrenamiento.

## ü§ù Contribuciones

Si encuentras mejoras o tienes sugerencias, ¬°son bienvenidas!

## üìÑ Licencia

MIT License

---

**Desarrollado para detecci√≥n de alta precisi√≥n en control de calidad de alimentos** ü•ú‚ú®
